{
  "name": "local-ollama-frontend",
  "version": "1.0.0",
  "description": "Goal: aim to make a front end that works well with Ollama LLMs. I want to be able to download LLM models from Ollama and have a good looking front that emulate ChatGPT",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "devDependencies": {
    "live-server": "^1.2.2",
    "nodemon": "^3.1.7"
  },
  "author": "",
  "license": "ISC",
  "dependencies": {
    "ollama": "^0.5.9"
  },
  "type": "module"
}
